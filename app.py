import streamlit as st
import pandas as pd
import plotly.express as px
import os 
from datetime import datetime
import numpy as np
import json 
import plotly.graph_objects as go


# --- 0. SIMULATION DES COUTS STRATEGIQUES (EN DUR) ---
COUT_RAPPEl_GRAVE_UNITAIRE = 50000.0  
COUT_RAPPEl_MINEUR_UNITAIRE = 5000.0   
COUT_LOGISTIQUE_JOUR_SUPP = 500.0      
SEUIL_IMR_ALERTE = 10.0                
risques_graves_keywords = "listeriose|salmonellose|e\.coli|blessures|allergene non declare|corps √©tranger" 

# Nouveaux Keywords pour les indicateurs de cause racine (simul√©s)
keywords_fournisseur = "allergene non declare|composition|etiquetage non conforme|matiere premiere"
keywords_logistique = "temperature|rupture de la chaine du froid|probleme de distribution|conditionnement"
keywords_recurrence_simule = ["salmonelle", "listeria", "e.coli"] # Pour la simulation du TRCR

# --- NOUVELLES CONSTANTES : LOGIQUE TRAFFIC LIGHT ---
SEUIL_VERT_MAX = 5     
SEUIL_ORANGE_MAX = 15  
# Seuils pour l'IPC (Indice de Pression Concurrentielle : IMR Marque / IMR March√©)
SEUIL_IPC_BON = 0.95   # Marque fait mieux que le march√©
SEUIL_IPC_MOYEN = 1.05 # Marque fait l√©g√®rement moins bien que le march√©

# Fonction pour attribuer un "Traffic Light" √† une fr√©quence
def get_traffic_light(count):
    if count <= SEUIL_VERT_MAX:
        return "üü¢ Faible (Green)"
    elif count <= SEUIL_ORANGE_MAX:
        return "üü† Mod√©r√© (Amber)"
    else:
        return "üî¥ Critique (Red)"

# Fonction pour attribuer la couleur de la fl√®che (delta_color)
# 'inverse' = True si une valeur plus basse est meilleure (ex: IMR)
def get_delta_color(value, target_threshold, inverse=False):
    if inverse:
        # Pour IMR : Plus bas que le seuil est Bon (Green), au-dessus est Mauvais (Red)
        if value <= target_threshold:
            return "normal"  # Green
        else:
            return "inverse" # Red
    else:
        # Pour IPC : Autour de 1.0 est neutre/bonne, tr√®s au-dessus est Mauvais
        if value < SEUIL_IPC_BON:
            return "normal" # Marque meilleure que le march√©
        elif value <= SEUIL_IPC_MOYEN:
            return "off"    # Proche du march√© (Neutre)
        else:
            return "inverse" # Marque moins bonne que le march√©
            
# Charger un GeoJSON simple pour la France
@st.cache_data(ttl=3600)
def load_geojson():
    """
    Tente de charger un fichier GeoJSON pour la cartographie.
    Si le fichier est manquant ou non support√©, retourne None.
    """
    geojson_path = "departements.geojson" 
    
    if os.path.exists(geojson_path):
        try:
            with open(geojson_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            st.sidebar.success("GeoJSON charg√© avec succ√®s pour la cartographie.")
            return data
        except Exception as e:
            st.sidebar.error(f"Erreur lors du chargement du GeoJSON : {e}")
            return None
    else:
        return None

# --- 1. CONFIGURATION ET MISE EN PAGE GLOBALE ---
st.set_page_config(page_title="Recall Analytics (RappelConso) - B2B PRO", layout="wide", initial_sidebar_state="expanded")
st.title("üõ°Ô∏è Recall Analytics ‚Äî Dashboard d'Intelligence March√© (B2B PRO) - Vue Strat√©gie DS")

# --- CSS INJECTION POUR L'ESTH√âTIQUE, LA POLICE ET LA S√âPARATION DES KPI ---
st.markdown("""
<style>
/* Style appliqu√© directement √† l'ensemble du widget st.metric */
div[data-testid="stMetric"] { 
    background-color: #FFFFFF; /* Fond blanc pour chaque bo√Æte de m√©trique */
    padding: 10px; /* Espace interne pour le texte */
    border-radius: 8px; /* Bords arrondis */
    border: 1px solid #e0e0e0; /* Bordure l√©g√®re */
    margin-bottom: 10px; /* Espace sous chaque m√©trique */
    box-shadow: 0 4px 6px rgba(0, 0, 0, 0.05); /* Ombre l√©g√®re */
    min-height: 100px; /* Hauteur minimale pour mieux contenir le texte */
    display: flex; /* Utilise flexbox pour un meilleur alignement interne */
    flex-direction: column; /* Organise label et valeur verticalement */
    justify-content: center; /* Centre verticalement le contenu */
    align-items: flex-start; /* Aligne le contenu √† gauche */
}

/* Augmente la taille de la police des valeurs st.metric */
div[data-testid="stMetricValue"] {
    font-size: 1.5rem; /* **AUGMENT√â : Taille de la valeur (ex: 15659)** */
    font-weight: 700;
    white-space: normal; /* Permet au texte de s'enrouler */
    overflow: hidden; /* Cache le texte qui d√©borde */
    text-overflow: ellipsis; /* Ajoute des points de suspension si le texte est coup√© */
    line-height: 1.2; /* Ajuste l'espacement entre les lignes si le texte s'enroule */
}

/* R√©duit la taille de la police des labels st.metric */
div[data-testid="stMetricLabel"] > div {
    font-size: 0.6rem; /* **R√âDUIT : Taille du label (ex: Total Rappels (P√©rim√®tre))** */
    font-weight: 600;
    opacity: 0.8;
    white-space: normal; /* Permet au texte de s'enrouler */
    overflow: hidden;
    text-overflow: ellipsis;
    line-height: 1.2; /* Ajuste l'espacement entre les lignes */
}

/* S√©pare visuellement les diff√©rentes sections (onglets) lors du scroll en donnant un fond l√©ger */
.stTabs [data-testid="stVerticalBlock"] {
    padding-top: 20px;
    padding-bottom: 20px;
    background-color: #F8F8F8; /* Gris tr√®s l√©ger pour contraster avec le fond de page */
    border-radius: 5px;
}
.stMetric {
    cursor: help; /* Rend l'ic√¥ne I plus intuitive */
}

</style>
""", unsafe_allow_html=True)
# --- FIN DE L'AJOUT CSS ---

st.markdown("""
**Focus DS :** Int√©gration des **Co√ªts Strat√©giques Simul√©**, **Indicateurs Denses** et **Analyse G√©ospatiale**.
""")

st.markdown("---")

# --- 2. FONCTIONS UTILITAIRES DE DATA PROCESSING (STABLES) ---

@st.cache_data(ttl=3600)
def load_data_from_csv(file_path="rappelconso_export.csv"):
    """Charge les donn√©es, standardise les colonnes et g√®re les s√©parateurs."""
    
    if not os.path.exists(file_path):
        st.error(f"‚ùå Fichier non trouv√© : '{file_path}'. Veuillez vous assurer que le fichier CSV t√©l√©charg√© est plac√© dans le m√™me dossier que l'application et porte ce nom.")
        return pd.DataFrame()
    
    df = pd.DataFrame()
    
    try:
        try:
            df = pd.read_csv(file_path, sep=";", encoding='utf-8')
            if df.shape[1] <= 1:
                df = pd.read_csv(file_path, sep=",", encoding='utf-8')
        except Exception:
            df = pd.read_csv(file_path, sep=",", encoding='utf-8')

        if df.empty or df.shape[1] <= 1:
            raise ValueError("Le fichier ne contient pas de donn√©es.")
            
        column_mapping = {
            "categorie_produit": "categorie_de_produit",
            "marque_produit": "nom_marque_du_produit",
            "motif_rappel": "motif_du_rappel",
            "numero_fiche": "reference_fiche",
            "lien_vers_la_fiche_rappel": "liens_vers_la_fiche_rappel",
            "date_debut_commercialisation_produit": "date_debut_commercialisation",
            "nom_fabricant_ou_marque": "nom_marque_du_produit",
            "denomination_sociale_du_producteur": "nom_marque_du_produit" # Ajout potentiel
        }
        
        rename_dict = {old_name: new_name for old_name, new_name in column_mapping.items() if old_name in df.columns and old_name != new_name}
        df = df.rename(columns=rename_dict)

        required_cols = ["categorie_de_produit", "nom_marque_du_produit", "motif_du_rappel", "distributeurs", "date_publication"]
        missing_cols = [c for c in required_cols if c not in df.columns]

        if missing_cols:
            st.error(f"‚ö†Ô∏è Alerte Colonnes : Le script ne trouve pas les colonnes n√©cessaires : **{', '.join(missing_cols)}**.")
            st.stop()
            
        if "date_publication" in df.columns:
            df["date_publication"] = pd.to_datetime(df["date_publication"], errors="coerce", utc=True)
            df = df.sort_values(by="date_publication", ascending=False) 
        
        if "date_debut_commercialisation" in df.columns:
            df["date_debut_commercialisation"] = pd.to_datetime(df["date_debut_commercialisation"], errors="coerce", utc=True)

        for col in ["distributeurs", "zone_geographique_de_vente", "risques_encourus", "motif_du_rappel", "categorie_de_produit", "nom_marque_du_produit", "identifiant_de_l_etablissement_d_ou_provient_le_produit", "etat_fiche", "denomination_vente", "sous_categorie_produit"]:
            if col in df.columns:
                df[col] = (df[col].astype(str)
                                 .str.lower()
                                 .str.replace("|", ";", regex=False)
                                 .str.replace(", ", ";", regex=False)
                                 .str.strip()
                                 .replace('nan', '', regex=False)
                                 .replace('', pd.NA) 
                )
        st.success(f"‚úÖ {len(df)} enregistrements charg√©s depuis {file_path}.")
        return df

    except Exception as e:
        st.error(f"‚ùå Erreur critique lors de la lecture du fichier CSV. Message : {e}")
        return pd.DataFrame()

def explode_column(df, column_name):
    """Divise une colonne de cha√Ænes de caract√®res s√©par√©es par des points-virgules (;) en lignes distinctes."""
    if column_name in df.columns and not df.empty:
        s = df[column_name].copy().astype(str).str.split(";")
        exploded_s = s.explode()
        exploded_df = exploded_s.to_frame(name=column_name)
        exploded_df = exploded_df.dropna(subset=[column_name])
        exploded_df[column_name] = exploded_df[column_name].str.strip()
        exploded_df = exploded_df[exploded_df[column_name] != 'nan']
        exploded_df = exploded_df[exploded_df[column_name] != '']
        return exploded_df
    return pd.DataFrame() 

def safe_filter_list(df_source, col_name, exploded=False):
    """Construit une liste de valeurs uniques pour les filtres."""
    if col_name not in df_source.columns or df_source.empty:
        return ["Toutes"]
    
    df_work = explode_column(df_source, col_name) if exploded else df_source.copy()

    if col_name in df_work.columns and not df_work.empty:
        raw_list = df_work[col_name].dropna().astype(str).unique().tolist()
        valid_list = [s.strip() for s in raw_list if s.strip() and s.strip() != 'nan']
        # Limite le nombre d'options si la liste est trop longue (par exemple, pour la d√©nomination de vente)
        if len(valid_list) > 1000:
            st.sidebar.warning(f"Liste trop longue pour {col_name}. Affichage des 1000 premi√®res.")
            return ["Toutes"] + sorted(list(set(valid_list[:1000])))
        return ["Toutes"] + sorted(list(set(valid_list)))
    
    return ["Toutes"]

# --- 3. CHARGEMENT ET FILTRES GLOBAUX ---
df = load_data_from_csv()
geojson_data = load_geojson() 

if df.empty:
    st.stop()

# Gestion de l'√©tat pour la marque s√©lectionn√©e (pour maintenir la coh√©rence)
if 'selected_marque' not in st.session_state:
    st.session_state['selected_marque'] = "Toutes"
    
# --- FILTRAGE PR√âLIMINAIRE PAR P√âRIODE (pour les listes d√©roulantes) ---
df_temp = df.copy()

# P√©riode
if "date_publication" in df_temp.columns:
    now = pd.Timestamp.now(tz='UTC') 
    periode_options = {
        "12 derniers mois": pd.DateOffset(months=12),
        "6 derniers mois": pd.DateOffset(months=6),
        "3 derniers mois": pd.DateOffset(months=3),
        "Toute la p√©riode": None
    }
    
    st.sidebar.header("‚öôÔ∏è Filtres Transversaux")
    
    # 1. P√©riode
    periode = st.sidebar.selectbox("P√©riode d'Analyse", list(periode_options.keys()))
    offset = periode_options[periode]
    if offset:
        df_temp = df_temp[df_temp["date_publication"] >= now - offset]
    else:
        df_temp = df.copy() 

# 2. Cat√©gorie de Produit
categories = safe_filter_list(df_temp, "categorie_de_produit")
cat = st.sidebar.selectbox("Cat√©gorie de Produit", categories)

# --- APPLICATION DU FILTRE CAT√âGORIE POUR COH√âRENCE MARQUE ---
df_coherence = df_temp.copy()
if cat != "Toutes" and "categorie_de_produit" in df_coherence.columns:
    df_coherence = df_coherence[df_coherence["categorie_de_produit"] == cat]
    
# 3. Marque (Benchmarking) - COH√âRENCE AVEC LA CAT√âGORIE
marques_coherentes = safe_filter_list(df_coherence, "nom_marque_du_produit")
current_marque_selection = st.session_state['selected_marque']
if current_marque_selection not in marques_coherentes:
    current_marque_selection = "Toutes"
marque = st.sidebar.selectbox("Marque (Benchmarking)", marques_coherentes, index=marques_coherentes.index(current_marque_selection))
st.session_state['selected_marque'] = marque # Sauvegarde pour le prochain cycle

# --- NOUVEAUX FILTRES BAS√âS SUR LES AUTRES CHAMPS ---

# 4. Sous-Cat√©gorie / Nature du Produit
col_nature = "denomination_vente"
if "sous_categorie_produit" in df.columns:
    col_nature = "sous_categorie_produit"
    
nature_list = safe_filter_list(df_coherence, col_nature)
nature = st.sidebar.selectbox(f"Nature du Produit ({col_nature.replace('_', ' ').title()})", nature_list)

# 5. Distributeur (Canal)
distributeurs_list = safe_filter_list(df_coherence, "distributeurs", exploded=True)
distrib = st.sidebar.selectbox("Distributeur (Canal)", distributeurs_list)

# 6. Motif de Rappel (Cause)
motifs_list = safe_filter_list(df_coherence, "motif_du_rappel")
motif = st.sidebar.selectbox("Motif de Rappel (Cause)", motifs_list)

# 7. Lieu de Vente (Zone G√©ographique)
zone_list = safe_filter_list(df_coherence, "zone_geographique_de_vente", exploded=True)
zone = st.sidebar.selectbox("Lieu de Vente (Zone G√©ographique)", zone_list)

# 8. Statut de la Fiche
statut_list = safe_filter_list(df_coherence, "etat_fiche")
statut = st.sidebar.selectbox("Statut de la Fiche", statut_list)


# --- APPLICATION FINALE DES FILTRES SUR LE DATAFRAME GLOBAL ---
df_filtered = df.copy() 

# 1. P√©riode
if offset:
    df_filtered = df_filtered[df_filtered["date_publication"] >= now - offset]

# 2. Cat√©gorie
if cat != "Toutes" and "categorie_de_produit" in df_filtered.columns:
    df_filtered = df_filtered[df_filtered["categorie_de_produit"] == cat]
    
# 3. Marque
if marque != "Toutes" and "nom_marque_du_produit" in df_filtered.columns:
    df_filtered = df_filtered[df_filtered["nom_marque_du_produit"] == marque]

# 4. Nature du Produit
if nature != "Toutes" and col_nature in df_filtered.columns:
    df_filtered = df_filtered[df_filtered[col_nature] == nature]
    
# 5. Distributeur
if distrib != "Toutes" and "distributeurs" in df_filtered.columns:
    df_filtered = df_filtered[df_filtered["distributeurs"].str.contains(distrib, case=False, na=False)]

# 6. Motif
if motif != "Toutes" and "motif_du_rappel" in df_filtered.columns:
    df_filtered = df_filtered[df_filtered["motif_du_rappel"].str.contains(motif, case=False, na=False)]

# 7. Zone
if zone != "Toutes" and "zone_geographique_de_vente" in df_filtered.columns:
    df_filtered = df_filtered[df_filtered["zone_geographique_de_vente"].str.contains(zone, case=False, na=False)]
    
# 8. Statut
if statut != "Toutes" and "etat_fiche" in df_filtered.columns:
    df_filtered = df_filtered[df_filtered["etat_fiche"] == statut]

# --- 4. CALCULS TRANSVERSAUX (KPIs) ---
total_rappels = len(df_filtered)

if total_rappels == 0:
    st.warning("‚ö†Ô∏è Aucun rappel trouv√© avec les filtres actuels. Veuillez ajuster la p√©riode ou les s√©lections dans la sidebar.")
    st.stop()


df_risques_exploded = explode_column(df_filtered, "risques_encourus")
df_motifs_exploded = explode_column(df_filtered, "motif_du_rappel")

# Risque principal
risque_principal = "N/A"
if not df_risques_exploded.empty and "risques_encourus" in df_risques_exploded.columns:
    risque_counts = df_risques_exploded["risques_encourus"].value_counts()
    if not risque_counts.empty:
        risque_major = next(iter(risque_counts.index), None)
        if risque_major:
            # Tronque le texte si "Listeria Monocytogenes" est pr√©sent
            if "listeria monocytogenes" in risque_major.lower():
                risque_principal = "Listeria Monocytogenes"
            else:
                risque_principal = risque_major.title()
    
# Vitesse de R√©ponse Moyenne (Proxy) - D√©lai Moyen (DM)
DM_label = "N/A"
DM_value = 0.0
df_temp_dates = pd.DataFrame()
if "date_debut_commercialisation" in df_filtered.columns and not df_filtered["date_debut_commercialisation"].isnull().all():
    df_temp_dates = df_filtered.dropna(subset=["date_publication", "date_debut_commercialisation"]).copy()
    if not df_temp_dates.empty:
        df_temp_dates["duree_commercialisation"] = (df_temp_dates["date_publication"] - df_temp_dates["date_debut_commercialisation"]).dt.days
        df_temp_dates = df_temp_dates[df_temp_dates["duree_commercialisation"] >= 0]
        if not df_temp_dates.empty:
            DM_value = df_temp_dates["duree_commercialisation"].mean()
            DM_label = f"{DM_value:.1f} jours"
    
# --- IMR FUNCTION (Rappel) ---
def calculate_imr(df_calc):
    if df_calc.empty or 'risques_encourus' not in df_calc.columns:
        return 0.0, 0.0, 0.0

    df_imr = df_calc.copy()
    
    # 1. Calcul de la gravit√©
    df_imr["is_risque_grave"] = df_imr["risques_encourus"].str.contains(risques_graves_keywords, case=False, na=False)
    df_imr['score_gravite'] = np.where(df_imr['is_risque_grave'], 2, 1) # Risque grave = poids 2, mineur = poids 1
    
    total_rappels_period = len(df_imr)
    total_score = df_imr['score_gravite'].sum()
    
    if total_rappels_period > 0:
        imr = (total_score / total_rappels_period) * 10 
        avg_gravite = total_score / total_rappels_period # Gravit√© Moyenne
    else:
        imr = 0.0
        avg_gravite = 0.0
        
    df_imr['cout_implicite'] = np.where(df_imr['is_risque_grave'], COUT_RAPPEl_GRAVE_UNITAIRE, COUT_RAPPEl_MINEUR_UNITAIRE)
    total_cout = df_imr['cout_implicite'].sum()

    return imr, total_cout, avg_gravite

# Calcul de l'IMR pour la marque filtr√©e
imr_marque, cout_marque, _ = calculate_imr(df_filtered)

# Calcul de l'IMR pour le march√© (pour la comparaison)
imr_marche_comp = 0.0
if "date_publication" in df.columns:
    df_marche_comp = df_temp.copy() # On prend le DF filtr√© uniquement par la P√©riode
    imr_marche_comp, _, _ = calculate_imr(df_marche_comp)

# NOUVEAU KPI: Indice de Pression Concurrentielle (IPC)
ipc_value = imr_marque / imr_marche_comp if imr_marche_comp > 0 else 0.0

# Calcul du % Rappels graves
pc_risques_graves = 0.0
pc_risques_graves_str = "N/A"
if total_rappels > 0 and 'risques_encourus' in df_filtered.columns:
    count_graves = df_filtered["risques_encourus"].str.contains(risques_graves_keywords, case=False, na=False).sum()
    pc_risques_graves = (count_graves / total_rappels * 100)
    pc_risques_graves_str = f"{pc_risques_graves:.1f}%"


# --- CALCULS NOUVEAUX KPIs ---

# 1. Taux d'Impact Fournisseur Critique (TIFC) - Simul√© sur motifs
tifc_value = 0.0
if total_rappels > 0 and 'motif_du_rappel' in df_filtered.columns:
    count_fournisseur_causes = df_filtered["motif_du_rappel"].str.contains(keywords_fournisseur, case=False, na=False).sum()
    tifc_value = (count_fournisseur_causes / total_rappels * 100)

# 2. Indice de S√©v√©rit√© du Risque (ISR) - Gravit√© Moyenne par Cat√©gorie Principale
isr_value = 0.0
if "categorie_de_produit" in df_filtered.columns:
    df_isr = df_filtered.copy()
    if not df_isr.empty:
        _, _, avg_gravite_filtered = calculate_imr(df_isr) # 1 √† 2
        # Ne compter que les rappels dans la cat√©gorie s√©lectionn√©e (si filtre actif)
        df_cat_active = df_filtered[df_filtered["categorie_de_produit"] == cat] if cat != "Toutes" else df_filtered
        
        count_cat = len(df_cat_active)
        
        # Le calcul de l'ISR doit se faire sur le p√©rim√®tre de la marque/cat√©gorie
        isr_value = avg_gravite_filtered * (count_cat / total_rappels) * 10 if total_rappels > 0 else 0.0
        
# 3. D√©lai d'Alerte Pr√©coce (DAP)
dap_value = 0.0
if not df_temp_dates.empty:
    # Simuler le DAP comme le pourcentage de rappels avec un d√©lai de commercialisation tr√®s court (< 7 jours)
    dap_count = df_temp_dates[df_temp_dates["duree_commercialisation"] <= 7].shape[0]
    dap_value = (dap_count / total_rappels) * 100 if total_rappels > 0 else 0.0

# 4. Taux d'Anomalie Logistique (TAL) - Simul√© sur motifs
tal_value = 0.0
if total_rappels > 0 and 'motif_du_rappel' in df_filtered.columns:
    count_log_causes = df_filtered["motif_du_rappel"].str.contains(keywords_logistique, case=False, na=False).sum()
    tal_value = (count_log_causes / total_rappels * 100)

# 5. Volatilit√© IMR (IMR_STD)
imr_std_value = 0.0
if marque != "Toutes" and "date_publication" in df_filtered.columns:
    df_trend = df.copy()
    # On filtre par la p√©riode uniquement (la marque sera filtr√©e apr√®s)
    if offset:
        df_trend = df_trend[df_trend["date_publication"] >= now - offset]
    df_trend["Mois"] = df_trend["date_publication"].dt.to_period("M")

    def compute_imr_per_month(df_input):
        if 'risques_encourus' not in df_input.columns or df_input.empty: return pd.Series(dtype='float64')
        df_input['is_risque_grave'] = df_input["risques_encourus"].str.contains(risques_graves_keywords, case=False, na=False)
        df_input['score_gravite'] = np.where(df_input['is_risque_grave'], 2, 1)
        imr_monthly = df_input.groupby('Mois').agg(
            Total_Score=('score_gravite', 'sum'),
            Total_Rappels=('score_gravite', 'count')
        )
        imr_monthly['IMR'] = np.where(imr_monthly['Total_Rappels'] > 0, 
                                      (imr_monthly['Total_Score'] / imr_monthly['Total_Rappels']) * 10, 
                                      0.0)
        return imr_monthly['IMR']

    imr_series = compute_imr_per_month(df_trend[df_trend["nom_marque_du_produit"] == marque])
    if len(imr_series) > 1:
        imr_std_value = imr_series.std()

# 6. Taux de R√©currence des Causes Racines (TRCR) - Simul√©
trcr_value = 0.0
if total_rappels > 0 and "risques_encourus" in df_filtered.columns:
    # Simuler la r√©currence si Listeria, Salmonella ou E.Coli apparaissent au moins deux fois.
    df_temp_recurrence = df_filtered.copy()
    df_temp_recurrence['Recurrence_Flag'] = df_temp_recurrence["risques_encourus"].apply(
        lambda x: any(kw in str(x) for kw in keywords_recurrence_simule)
    )
    if df_temp_recurrence['Recurrence_Flag'].sum() >= 2:
        # TRCR simul√© √† 15% si on d√©tecte au moins 2 cas de risque haut
        trcr_value = 15.0 
    else:
        trcr_value = 2.0

# 7. Ratio Risque/Opportunit√© (RRO) - Simulation sur la cat√©gorie
rro_value = 0.0
if total_rappels > 0 and "categorie_de_produit" in df_filtered.columns:
    rappels_par_cat = df_marche_comp.groupby("categorie_de_produit").size() if 'df_marche_comp' in locals() else pd.Series()
    
    # Calculer l'IMR de la cat√©gorie sur le march√© filtr√©
    imr_cat_marche = 0.0
    if cat != "Toutes":
        imr_cat_marche, _, _ = calculate_imr(df_marche_comp[df_marche_comp["categorie_de_produit"] == cat])
    else:
        imr_cat_marche = imr_marche_comp

    if imr_cat_marche > 0 and cat != "Toutes" and cat in rappels_par_cat:
        # RRO = IMR_Marque / IMR_Cat√©gorie_March√© (Facteur de risque pur)
        rro_value = imr_marque / imr_cat_marche 
    else:
        rro_value = imr_marque * 0.5 / 10


# --- CALCUL DES COULEURS TRAFFIC LIGHT ---
# 1. IMR de la Marque (plus bas est meilleur)
imr_marque_delta = imr_marque - (SEUIL_IMR_ALERTE / 2) # Arbitraire pour simuler une 'variation' par rapport √† un objectif de 5
imr_marque_color = get_delta_color(imr_marque, SEUIL_IMR_ALERTE, inverse=True)

# 2. IPC (Indice de Pression Concurrentielle) (cible = 1.0)
# Le delta est calcul√© par rapport √† l'objectif 1.0
ipc_delta = ipc_value - 1.0 
ipc_color = get_delta_color(ipc_value, 1.0, inverse=False)


# --- 5. STRUCTURE DU TABLEAU DE BORD PAR ACTEUR (TABS) ---

tab1, tab2, tab3 = st.tabs(["üè≠ Fabricants & Marques", "üõí Distributeurs & Retailers", "üî¨ Risque & Conformit√©"])


# ----------------------------------------------------------------------
# TAB 1: FABRICANTS & MARQUES (BENCHMARKING IMR & RISQUE FOURNISSEUR)
# ----------------------------------------------------------------------
with tab1:
    st.header("üéØ Intelligence Concurrentielle & Ma√Ætrise du Risque Fournisseur")
    
    # --- FEUILLE DE ROUTE FABRICANTS ---
    with st.expander("üìñ Feuille de Route : Filtrage et Interpr√©tation pour Fabricants/Marques"):
        st.markdown("""
        Cet onglet est con√ßu pour les √©quipes de **Direction G√©n√©rale**, **Qualit√© Produit**, et **Achats**.
        
        ### ‚öôÔ∏è Strat√©gie de Filtrage Recommand√©e
        | √âtape | Filtre √† Appliquer | Objectif du Filtre |
        | :---: | :--- | :--- |
        | **1.** | **P√©riode d'Analyse** | S√©lectionnez **"12 derniers mois"** pour une vue annuelle stable, ou **"3 derniers mois"** pour identifier rapidement les tendances √©mergentes. |
        | **2.** | **Cat√©gorie de Produit** | **Filtrer par votre Cat√©gorie principale.** Calibre l'IMR du March√© (benchmark) et concentre l'analyse sur vos concurrents directs. |
        | **3.** | **Marque (Benchmarking)** | **S√©lectionnez votre propre marque** (et non "Toutes"). Active le calcul de l'IMR de la Marque, de l'IPC et de la Tendance. |
        
        ### üìä Interpr√©tation des Indicateurs Cl√©s
        | Indicateur (KPI) | Lecture et Objectif | Interpr√©tation Strat√©gique |
        | :--- | :--- | :--- |
        | **IMR de la Marque** | Mesure la gravit√© pond√©r√©e des rappels de votre marque. **Cible : le plus bas possible (ex: < 5)**. | **Performance :** S'il est **√©lev√© (ex: > 10)**, vous avez un probl√®me de ma√Ætrise du risque grave, souvent li√© √† la s√©curit√© alimentaire (Listeria, Salmonella). |
        | **Indice de Pression Concurrentielle (IPC)** | Votre IMR / IMR du March√©. **Cible : < 1.0 (Id√©alement 0.90-0.95)**. | **Benchmarking :** Si **IPC > 1.0**, vous √™tes **moins performant/plus risqu√©** que la moyenne de votre cat√©gorie. Si **IPC < 1.0**, vous avez un avantage concurrentiel sur la ma√Ætrise du risque. |
        | **Taux d'Impact Fournisseur Critique (TIFC)** | % des rappels dont la cause est externe. **Cible : le plus bas possible (< 5%)**. | **Achats/Fournisseurs :** Un TIFC √©lev√© pointe un d√©faut dans l'audit ou la sp√©cification de vos fournisseurs T1. |
        """)
    
    # --- KPI FABRICANT (4 colonnes x 2 lignes = 8 KPIs) ---
    col1, col2, col3, col4 = st.columns(4)
    col5, col6, col7, col8 = st.columns(4)
    
    # LIGNE 1 : PRESSION & CONTEXTE
    with col1:
        st.metric("Total Rappels (P√©rim√®tre)", total_rappels, 
            help="Nombre total de fiches de rappel publi√©es, tenant compte de la p√©riode et des filtres s√©lectionn√©s. üìà **Message :** Mesure la **pression volume** globale.")
    with col2:
        st.metric("IMR du March√©", f"{imr_marche_comp:.2f}",
            help="Indice de Ma√Ætrise du Risque (IMR) calcul√© sur l'ensemble des marques dans la p√©riode filtr√©e. üìä **Benchmark :** Point de r√©f√©rence pour √©valuer la performance de votre marque.")
    with col3:
        st.metric("Risque Principal", risque_principal,
            help="Le risque encouru le plus fr√©quemment mentionn√©. ‚ö†Ô∏è **Priorit√© :** Indique le danger sanitaire ou physique majeur √† adresser en priorit√©.")
    with col4:
        st.metric("Taux d'Impact Fournisseur Critique (TIFC)", f"{tifc_value:.1f}%",
            help="Proportion des rappels dont la cause est li√©e √† une non-conformit√© fournisseur. üö® **Contr√¥le :** Un TIFC √©lev√© sugg√®re des audits fournisseurs insuffisants ou une faible sp√©cification d'achat.")
    
    # LIGNE 2 : PERFORMANCE & PROJECTION
    with col5:
        # IMR de la Marque avec Traffic Light (Bas est meilleur)
        st.metric("IMR de la Marque", f"{imr_marque:.2f}", delta=f"Cible < {SEUIL_IMR_ALERTE}", delta_color=imr_marque_color,
            help="Indice de Ma√Ætrise du Risque de votre marque (Score Gravit√© Pond√©r√©). üéØ **Performance :** L'objectif est de maintenir un score bas (moins de risque) et stable.")
    with col6:
        # IPC avec Traffic Light (Proche de 1.0 est meilleur)
        st.metric("Indice de Pression Concurrentielle (IPC)", f"{ipc_value:.2f}", delta=f"Vs Cible 1.0 (March√©)", delta_color=ipc_color, 
            help="Formule : IMR Marque / IMR March√©. üìâ **Positionnement :** Un score **sup√©rieur √† 1.0** indique une **sous-performance** (votre marque est plus risqu√©e que la moyenne du march√©).")
    with col7:
        st.metric("Co√ªt Implicite", f"{cout_marque:,.0f} ‚Ç¨",
            help="Co√ªt de rappel simul√© (Graves x 50K‚Ç¨ + Mineurs x 5K‚Ç¨). üí∞ **Impact :** Chiffre la perte financi√®re minimale due √† la crise.")
    with col8:
        st.metric("Indice de S√©v√©rit√© du Risque (ISR)", f"{isr_value:.2f}",
            help="Gravit√© Moyenne Pond√©r√©e par le Volume de Rappels dans la Cat√©gorie. üß≠ **Strat√©gie :** Aide √† r√©orienter les budgets de pr√©vention vers les cat√©gories de produits les plus dangereuses.")

    st.markdown("### Analyse de Positionnement et Causes Racines")
    st.markdown("---") # S√©paration visuelle
    col_gauche, col_droite = st.columns(2)

    with col_gauche:
        st.subheader("1. Benchmark : Part de Rappel par Marque (SoR)")
        
        if "nom_marque_du_produit" in df_filtered.columns and total_rappels > 0:
            top_marques = df_filtered["nom_marque_du_produit"].value_counts(normalize=True).mul(100).reset_index().rename(columns={
                "nom_marque_du_produit": "Marque", 
                "proportion": "Part_de_Rappel_pourcent"
            })
            top_marques = top_marques.head(10)
            fig_sor = px.bar(top_marques, y="Marque", x="Part_de_Rappel_pourcent", orientation='h', title="Top 10 : Contribution (%) aux rappels du march√©",
                             color='Part_de_Rappel_pourcent', color_continuous_scale=px.colors.sequential.Plotly3)
            fig_sor.update_layout(yaxis={'categoryorder':'total ascending'}, xaxis_title="Part (%) des Rappels Filtr√©s")
            st.plotly_chart(fig_sor, use_container_width=True)
        else:
            st.info("Aucune donn√©e pour le benchmarking des marques.")

    with col_droite:
        st.subheader("2. Tendance : IMR de la Marque vs. March√© (Courbe de Contr√¥le)")
        if marque != "Toutes" and "date_publication" in df_filtered.columns:
            
            df_trend = df.copy()
            if offset:
                df_trend = df_trend[df_trend["date_publication"] >= now - offset]
            df_trend["Mois"] = df_trend["date_publication"].dt.to_period("M")

            def compute_imr_per_month(df_input):
                if 'risques_encourus' not in df_input.columns or df_input.empty:
                    return pd.DataFrame()
                    
                df_input['is_risque_grave'] = df_input["risques_encourus"].str.contains(risques_graves_keywords, case=False, na=False)
                df_input['score_gravite'] = np.where(df_input['is_risque_grave'], 2, 1)
                
                imr_monthly = df_input.groupby('Mois').agg(
                    Total_Score=('score_gravite', 'sum'),
                    Total_Rappels=('score_gravite', 'count')
                ).reset_index()
                
                imr_monthly['IMR'] = np.where(imr_monthly['Total_Rappels'] > 0, 
                                              (imr_monthly['Total_Score'] / imr_monthly['Total_Rappels']) * 10, 
                                              0.0)
                imr_monthly['Mois'] = imr_monthly['Mois'].dt.to_timestamp()
                return imr_monthly[['Mois', 'IMR']]

            df_imr_marque = compute_imr_per_month(df_trend[df_trend["nom_marque_du_produit"] == marque])
            df_imr_marche = compute_imr_per_month(df_trend)
            
            if not df_imr_marque.empty or not df_imr_marche.empty:
                df_imr_marche = df_imr_marche.rename(columns={'IMR': 'IMR_March√©'})
                
                df_comp = pd.merge(df_imr_marque.rename(columns={'IMR': f'IMR_{marque.title()}'}), df_imr_marche, on='Mois', how='outer').fillna(0)
                
                fig_trend = px.line(df_comp, x="Mois", y=[f"IMR_{marque.title()}", "IMR_March√©"], 
                                    title=f"√âvolution Mensuelle de l'IMR : {marque.title()} vs. March√© (Seuil Alerte {SEUIL_IMR_ALERTE})",
                                    labels={"value": "IMR (Score Pond√©r√©)", "Mois": "Mois"},
                                    color_discrete_map={f'IMR_{marque.title()}': '#2C3E50', 'IMR_March√©': '#BDC3C7'},
                                    line_shape='spline', markers=True)
                
                fig_trend.add_hline(y=SEUIL_IMR_ALERTE, line_dash="dot", line_color="red", 
                                    annotation_text="Seuil Alerte IMR", 
                                    annotation_position="top right")

                st.plotly_chart(fig_trend, use_container_width=True)
            else:
                st.info("S√©lectionnez une marque dans la sidebar pour afficher l'IMR et la tendance.")

    st.markdown("---")
    # Donut Chart NCF Fournisseur / Matrice Corr√©lation
    total_fournisseurs_t1 = 100 # Simul√©
    total_fournisseurs_impactes = 15 # Simul√©
    if 'identifiant_de_l_etablissement_d_ou_provient_le_produit' in df_filtered.columns and total_fournisseurs_impactes > 0:
        st.subheader("3. D√©pendance au Risque Fournisseur (NCF T1)")
        df_ncf = pd.DataFrame({
            'Type': ['Fournisseurs Impact√©s', 'Fournisseurs non Impact√©s'],
            'Count': [total_fournisseurs_impactes, max(0, total_fournisseurs_t1 - total_fournisseurs_impactes)]
        })
        fig_donut = px.pie(df_ncf, values='Count', names='Type', hole=.5, 
                           title=f"Taux de Non-Conformit√© (NCF) des {total_fournisseurs_t1} Fournisseurs T1 (Simul√©)",
                           color_discrete_sequence=['#E74C3C', '#2ECC71'])
        st.plotly_chart(fig_donut, use_container_width=True)
    else:
         st.markdown("### 3. Corr√©lation : Matrice des Motifs vs. Risques")
         if "risques_encourus" in df_filtered.columns and "motif_du_rappel" in df_filtered.columns:
            df_corr = df_filtered.copy()
            df_corr["Motif_court"] = df_corr["motif_du_rappel"].str.split(r'[;.,]').str[0].str.strip()
            
            df_exploded_motif_risque = df_corr.assign(risques_encourus=df_corr['risques_encourus'].str.split(';')).explode('risques_encourus')
            df_exploded_motif_risque['risques_encourus'] = df_exploded_motif_risque['risques_encourus'].str.strip()
            
            if df_exploded_motif_risque.empty:
                st.info("Pas assez de donn√©es pour g√©n√©rer la matrice de corr√©lation Motif/Risque (apr√®s explosion des risques).")
            else:
                cooccurrence = df_exploded_motif_risque.groupby(['Motif_court', 'risques_encourus']).size().reset_index(name='Nombre')
                cooccurrence = cooccurrence[cooccurrence['Nombre'] > 0]
                
                top_motifs_list = cooccurrence['Motif_court'].value_counts().head(5).index
                top_risques_list = cooccurrence['risques_encourus'].value_counts().head(5).index
                
                cooccurrence_filtered = cooccurrence[
                    cooccurrence['Motif_court'].isin(top_motifs_list) & 
                    cooccurrence['risques_encourus'].isin(top_risques_list)
                ]
                
                if not cooccurrence_filtered.empty:
                    fig_heatmap = px.density_heatmap(cooccurrence_filtered, x="Motif_court", y="risques_encourus", z="Nombre", 
                                                     title="Fr√©quence d'association des Top 5 Motifs et Top 5 Risques",
                                                     text_auto=True, color_continuous_scale="Plasma")
                    st.plotly_chart(fig_heatmap, use_container_width=True)
                else:
                    st.info("Pas assez de donn√©es pour g√©n√©rer la matrice de corr√©lation Motif/Risque.")
         else:
             st.info("Colonnes de risque et/ou de motif manquantes pour la matrice.")


# ----------------------------------------------------------------------
# TAB 2: DISTRIBUTEURS & RETAILERS (MATRICE DE RISQUE LOGISTIQUE & G√âOSPATIALIT√â)
# ----------------------------------------------------------------------
with tab2:
    st.header("üõí Analyse du Canal de Distribution & Risque Logistique")

    # --- FEUILLE DE ROUTE DISTRIBUTEURS ---
    with st.expander("üìñ Feuille de Route : Filtrage et Interpr√©tation pour Distributeurs/Retailers"):
        st.markdown("""
        Cet onglet est con√ßu pour les √©quipes de **Supply Chain**, **Logistique**, et **Op√©rations Commerciales**.

        ### ‚öôÔ∏è Strat√©gie de Filtrage Recommand√©e
        | √âtape | Filtre √† Appliquer | Objectif du Filtre |
        | :---: | :--- | :--- |
        | **1.** | **P√©riode d'Analyse** | **"12 ou 6 derniers mois"** pour analyser l'efficacit√© de vos proc√©dures de retrait/rappel et les risques logistiques. |
        | **2.** | **Distributeur (Canal)** | **S√©lectionnez votre r√©seau ou un concurrent.** Isole l'impact des rappels au sein du canal sp√©cifique pour le benchmark. |
        | **3.** | **Motif de Rappel** | **(Optionnel)** Filtrer sur les motifs logistiques (ex: "temp√©rature", "rupture") pour calculer le Taux d'Anomalie Logistique (TAL) sp√©cifique. |
        | **4.** | **Lieu de Vente (Zone G√©ographique)** | **(Optionnel)** Isole une r√©gion ou un d√©partement pour analyser les probl√©matiques locales. |

        ### üìä Interpr√©tation des Indicateurs Cl√©s
        | Indicateur (KPI) | Lecture et Objectif | Interpr√©tation Strat√©gique |
        | :--- | :--- | :--- |
        | **D√©lai Moyen (DM) Avant Rappel** | Dur√©e moyenne entre la commercialisation et la publication du rappel. **Cible : le plus bas possible**. | **R√©activit√© :** Un DM long signifie une exposition prolong√©e des consommateurs. Implique une am√©lioration des alertes en magasin et des syst√®mes d'information. |
        | **Taux d'Anomalie Logistique (TAL)** | % des rappels li√©s √† des causes de transport, stockage ou distribution. **Cible : le plus bas possible (< 3%)**. | **Supply Chain :** Un TAL √©lev√© pointe directement des faiblesses dans le r√©seau de distribution, le respect de la cha√Æne du froid, ou le stockage en entrep√¥t. |
        | **Matrice de Priorisation du Risque** | Classement des distributeurs selon la fr√©quence et le d√©lai avant rappel. | **N√©gociation/Audit :** Les partenaires dans le quadrant **"Risque √âlev√©"** (Fr√©quence √âlev√©e + D√©lai Long) sont les plus co√ªteux et doivent √™tre audit√©s en priorit√©. |
        """)

    # --- KPI DISTRIBUTEUR (4 colonnes x 2 lignes = 8 KPIs) ---
    col1, col2, col3, col4 = st.columns(4)
    col5, col6, col7, col8 = st.columns(4)
    
    # LIGNE 1 : PRESSION & CONTEXTE
    with col1:
        st.metric("Total Rappels (Filtr√©)", total_rappels,
            help="Nombre total de fiches de rappel publi√©es, tenant compte de la p√©riode et des filtres s√©lectionn√©s. üìà **Message :** Mesure la **pression volume** globale.")
    with col2:
        st.metric("Score d'Exposition G√©ographique (Simul√©)", "√âlev√©" if total_rappels > SEUIL_ORANGE_MAX * 5 else "Faible",
            help="√âvaluation simplifi√©e de l'impact potentiel du rappel (volume et densit√©). üó∫Ô∏è **Logistique :** Un score √©lev√© signifie que la charge logistique et la pression m√©diatique sont maximales pour les zones de vente concern√©es.")
    with col3:
        st.metric("D√©lai Moyen (DM) Avant Rappel", DM_label,
            help="Moyenne des (Date Publication - Date D√©but Commercialisation) en jours. ‚è±Ô∏è **R√©activit√© :** Plus ce d√©lai est long, plus l'exposition du consommateur au risque a √©t√© importante (faible r√©activit√© interne).")
    with col4:
        st.metric("Taux d'Anomalie Logistique (TAL)", f"{tal_value:.1f}%",
            help="Pourcentage des rappels dont le motif est li√© √† un d√©faut de distribution/stockage. üì¶ **Cha√Æne de Froid :** Un TAL √©lev√© pointe directement vers des faiblesses dans le r√©seau de distribution ou le stockage en magasin.")
        
    # LIGNE 2 : PERFORMANCE & PROJECTION
    with col5:
        st.metric("D√©lai d'Alerte Pr√©coce (DAP)", f"{dap_value:.1f}%",
            help="Proportion des rappels dont la dur√©e de commercialisation a √©t√© tr√®s courte (< 7 jours). üí° **Efficacit√© :** Un DAP √©lev√© peut indiquer que vos syst√®mes d'alerte internes sont lents, ou au contraire que le contr√¥le externe est tr√®s rapide.")
    with col6:
        st.metric("Co√ªt Logistique Max/Distributeur", f"{COUT_LOGISTIQUE_JOUR_SUPP:,.0f} ‚Ç¨ / Jour",
            help="Co√ªt simul√© d'un jour d'exposition au risque logistique par rappel. üí∏ **N√©gociation :** Sert de base pour prioriser les distributeurs ayant le risque de *dur√©e* le plus co√ªteux.")
    with col7:
        if "distributeurs" in df_filtered.columns:
            df_distrib_exploded = explode_column(df_filtered, 'distributeurs')
            distrib_counts = df_distrib_exploded['distributeurs'].value_counts()
            densite_distrib = distrib_counts.mean() if not distrib_counts.empty else 0.0
            st.metric("Densit√© Moy. Rappel/Distributeur", f"{densite_distrib:.1f}",
                help="Total Rappels (Filtr√©) / Nombre de Distributeurs Uniques Impliqu√©s. ‚öñÔ∏è **Concentration :** Mesure la fr√©quence d'incidents chez les partenaires. Un ratio √©lev√© indique une d√©pendance √† des distributeurs plus risqu√©s.")
        else:
            st.metric("Densit√© Moy. Rappel/Distributeur", "N/A",
                help="Total Rappels (Filtr√©) / Nombre de Distributeurs Uniques Impliqu√©s. ‚öñÔ∏è **Concentration :** Mesure la fr√©quence d'incidents chez les partenaires. Un ratio √©lev√© indique une d√©pendance √† des distributeurs plus risqu√©s.")
    with col8:
        taux_couverture_rappel = 85.0 # Simul√©
        st.metric("Taux de Couverture du Rappel (TCR) (Simul√©)", f"{taux_couverture_rappel:.1f}%", 
            help="Pourcentage des zones g√©ographiques couvertes par une action de retrait document√©e. ‚úÖ **Conformit√© :** √âvalue l'efficacit√© et l'exhaustivit√© de l'ex√©cution du plan de retrait sur le terrain.")


    st.markdown("### 1. Matrice de Priorisation du Risque Distributeur (Bubble Chart)")
    st.markdown("---") # S√©paration visuelle
    
    if "date_debut_commercialisation" in df_filtered.columns and "distributeurs" in df_filtered.columns:
            
        df_reponse = df_filtered.dropna(subset=["date_publication", "date_debut_commercialisation", "distributeurs"]).copy()
        
        if df_reponse.empty:
            st.info("‚ö†Ô∏è Les filtres appliqu√©s n'ont g√©n√©r√© aucune donn√©e valide pour la Matrice de Risque Distributeur.")
        else:
            df_reponse = df_reponse.assign(distributeurs=df_reponse['distributeurs'].str.split(';')).explode('distributeurs')
            df_reponse['distributeurs'] = df_reponse['distributeurs'].str.strip()
            df_reponse = df_reponse[df_reponse['distributeurs'] != '']
            
            if df_reponse.empty:
                st.info("‚ö†Ô∏è Les donn√©es de distributeurs sont vides apr√®s nettoyage et explosion. (V√©rifiez les valeurs de la colonne 'distributeurs')")
            else:
                df_reponse["D√©lai_Jours"] = (df_reponse["date_publication"] - df_reponse["date_debut_commercialisation"]).dt.days
                df_reponse = df_reponse[df_reponse["D√©lai_Jours"] >= 0]
                
                if 'risques_encourus' in df_reponse.columns:
                    df_reponse['is_risque_grave'] = df_reponse["risques_encourus"].str.contains(risques_graves_keywords, case=False, na=False)
                    df_reponse['Score_Gravite'] = np.where(df_reponse['is_risque_grave'], 2, 1) 
                else:
                    df_reponse['Score_Gravite'] = 1
                
                avg_distrib = df_reponse.groupby("distributeurs").agg(
                    D√©lai_Moyen_Jours=('D√©lai_Jours', 'mean'),
                    Nb_Rappels=('D√©lai_Jours', 'count'),
                    Gravite_Moyenne=('Score_Gravite', 'mean')
                ).reset_index()
                
                # Co√ªt d'exposition au risque simul√© (en k‚Ç¨)
                avg_distrib['Co√ªt_Risque_Simul√©'] = avg_distrib['D√©lai_Moyen_Jours'] * avg_distrib['Nb_Rappels'] * avg_distrib['Gravite_Moyenne'] * COUT_LOGISTIQUE_JOUR_SUPP / 1000 
                
                if not avg_distrib.empty:
                    fig_bubble = px.scatter(avg_distrib, 
                                            x="D√©lai_Moyen_Jours", 
                                            y="Nb_Rappels", 
                                            size="Co√ªt_Risque_Simul√©", 
                                            color="Gravite_Moyenne",
                                            hover_name="distributeurs",
                                            size_max=40,
                                            title="Matrice de Priorisation du Risque Distributeur (Co√ªt Logistique/Jours Simul√©)",
                                            labels={
                                                "D√©lai_Moyen_Jours": "Axe X: D√©lai Moyen avant Rappel (Jours) ‚û° Risque de Dur√©e",
                                                "Nb_Rappels": "Axe Y: Fr√©quence des Rappels ‚û° Risque de Volume",
                                                "Gravite_Moyenne": "Gravit√© Moyenne (Couleur)",
                                                "Co√ªt_Risque_Simul√©": "Co√ªt d'Exposition au Risque Simul√© (k‚Ç¨)"
                                            },
                                            color_continuous_scale=px.colors.sequential.YlOrRd)
                    
                    if not avg_distrib.empty:
                        fig_bubble.add_vline(x=avg_distrib['D√©lai_Moyen_Jours'].median(), line_dash="dash", line_color="#34495E")
                        fig_bubble.add_hline(y=avg_distrib['Nb_Rappels'].median(), line_dash="dash", line_color="#34495E")

                    fig_bubble.update_layout(xaxis_range=[0, avg_distrib['D√©lai_Moyen_Jours'].max() * 1.1])
                    st.plotly_chart(fig_bubble, use_container_width=True)
                else:
                    st.info("Donn√©es insuffisantes pour la matrice de risque distributeur (apr√®s agr√©gation).")
    else:
        st.info("Colonnes de date de commercialisation et/ou distributeurs manquantes.")
        
    
    st.markdown("---") # S√©paration visuelle
    st.subheader("2. Score de Risque G√©ographique (Traffic Light) ")
    st.caption(f"Seuils : üü¢ 0-{SEUIL_VERT_MAX} rappels, üü† {SEUIL_VERT_MAX+1}-{SEUIL_ORANGE_MAX} rappels, üî¥ >{SEUIL_ORANGE_MAX} rappels.")

    if "zone_geographique_de_vente" in df_filtered.columns:
        df_geo = explode_column(df_filtered, "zone_geographique_de_vente")
        
        # Tentative d'extraction du code d√©partemental/r√©gional (tr√®s simplifi√©)
        df_geo['zone_clean'] = df_geo['zone_geographique_de_vente'].str.extract(r'(\d{2,3})') 
        df_geo.loc[df_geo['zone_clean'].isna(), 'zone_clean'] = df_geo.loc[df_geo['zone_clean'].isna(), 'zone_geographique_de_vente'].str.split('-').str[0].str.strip()
        df_geo = df_geo.dropna(subset=['zone_clean'])
        
        # Agr√©gation par zone
        geo_counts = df_geo.groupby('zone_clean').size().reset_index(name='Nombre_Rappels')
        
        if not geo_counts.empty:
            # Attribution du Traffic Light
            geo_counts['Niveau_Risque'] = geo_counts['Nombre_Rappels'].apply(get_traffic_light)
            
            # Affichage de la carte Choropleth si GeoJSON disponible (avec attribution de couleur)
            if geojson_data:
                
                st.info("‚úÖ GeoJSON d√©tect√©. Affichage de la carte de risque g√©ospatial (Taille ajust√©e).")
                
                def get_plotly_color(count):
                    if count <= SEUIL_VERT_MAX: return '#2ECC71' # Green
                    elif count <= SEUIL_ORANGE_MAX: return '#F39C12' # Orange
                    else: return '#E74C3C' # Red
                
                geo_counts['Couleur_Hex'] = geo_counts['Nombre_Rappels'].apply(get_plotly_color)
                
                try:
                    fig_map = px.choropleth(geo_counts,
                                            geojson=geojson_data,
                                            locations='zone_clean',
                                            featureidkey="properties.code", 
                                            color='Nombre_Rappels', 
                                            hover_name='zone_clean',
                                            color_continuous_scale=["#2ECC71", "#F39C12", "#E74C3C"], 
                                            range_color=[0, SEUIL_ORANGE_MAX + 1], 
                                            title="R√©partition G√©ospatiale du Risque (Traffic Light)",
                                            height=1000) 
                    
                    fig_map.update_geos(
                        fitbounds="locations", 
                        visible=False,
                        center={"lat": 46.603354, "lon": 1.888334}, 
                        projection_scale=3 
                    )
                    fig_map.update_layout(coloraxis_showscale=False) 
                    
                    st.plotly_chart(fig_map, use_container_width=True)
                except Exception as e:
                    st.warning(f"‚ö†Ô∏è Impossible d'afficher la carte Choropleth (Erreur Plotly : {e}). V√©rifiez la correspondance des codes dans le GeoJSON.")
                    
                    # Affichage du tableau de bord Traffic Light (M√©thode de repli)
                    st.dataframe(geo_counts[['zone_clean', 'Nombre_Rappels', 'Niveau_Risque']].rename(columns={
                        'zone_clean': 'Zone G√©ographique', 
                        'Nombre_Rappels': 'Nbre de Rappels'
                    }).sort_values(by='Nbre de Rappels', ascending=False), 
                    hide_index=True, use_container_width=True)

            else:
                # Affichage du tableau de bord Traffic Light (par d√©faut si pas de GeoJSON)
                st.info("Impossible de charger la carte Choropleth (GeoJSON manquant). Affichage du tableau de bord Traffic Light par Zone de Vente.")
                
                st.markdown("---")
                st.markdown("#### Tableau de Risque G√©ographique (Repli)")
                st.dataframe(geo_counts[['zone_clean', 'Nombre_Rappels', 'Niveau_Risque']].rename(columns={
                    'zone_clean': 'Zone G√©ographique', 
                    'Nombre_Rappels': 'Nbre de Rappels'
                }).sort_values(by='Nbre de Rappels', ascending=False), 
                hide_index=True, use_container_width=True)
                
        else:
            st.info("Donn√©es de zone g√©ographique de vente insuffisantes pour l'analyse Traffic Light.")
    else:
        st.info("Colonne 'zone_geographique_de_vente' manquante pour l'analyse g√©ospatiale.")


# ----------------------------------------------------------------------
# TAB 3: RISQUE & CONFORMIT√â (D√âRIVE DES CAUSES RACINES & PROFIL DE RISQUE)
# ----------------------------------------------------------------------
with tab3:
    st.header("üî¨ √âvaluation de la Gravit√© et Tendance du Risque (Assurance & Conseil)")
    
    # --- FEUILLE DE ROUTE CONFORMIT√â ---
    with st.expander("üìñ Feuille de Route : Filtrage et Interpr√©tation pour Risque/Conformit√©/Audit"):
        st.markdown("""
        Cet onglet est con√ßu pour les √©quipes d'**Audit Interne**, **Qualit√©/HACCP** et les **Consultants en Risque**.

        ### ‚öôÔ∏è Strat√©gie de Filtrage Recommand√©e
        | √âtape | Filtre √† Appliquer | Objectif du Filtre |
        | :---: | :--- | :--- |
        | **1.** | **P√©riode d'Analyse** | **"12 derniers mois"** pour la Volatilit√© IMR (IMR_STD) ou **"Toute la p√©riode"** pour le Taux de R√©currence (TRCR). |
        | **2.** | **Cat√©gorie de Produit** | **S√©lectionner la cat√©gorie la plus risqu√©e** (celle avec l'IMR le plus √©lev√© dans l'onglet 1) pour une analyse approfondie. |
        | **3.** | **Marque / Nature du Produit** | **(Optionnel)** Isolez les produits sp√©cifiques pour comprendre l'origine de la Volatilit√© (DCR). |
        | **4.** | **Statut de la Fiche** | Filtrer sur **"Rappel en cours"** pour √©valuer la charge de risque actuelle non r√©solue. |

        ### üìä Interpr√©tation des Indicateurs Cl√©s
        | Indicateur (KPI) | Lecture et Objectif | Interpr√©tation Strat√©gique |
        | :--- | :--- | :--- |
        | **% Rappels Graves** | Proportion de rappels concernant des risques majeurs (Listeria, Salmonelle, corps √©tranger). **Cible : 0%**. | **Audit Critique :** Si > 5%, r√©vision urgente des CCP (Critical Control Points) et des plans HACCP. |
        | **Volatilit√© IMR (IMR_STD)** | Mesure l'instabilit√© de votre risque dans le temps (√âcart-type de l'IMR mensuel). **Cible : le plus bas possible**. | **Ma√Ætrise :** Une forte volatilit√© indique un manque de stabilit√© dans le syst√®me qualit√© (contr√¥les non syst√©matiques ou al√©atoires). |
        | **Taux de R√©currence des Causes Racines (TRCR)** | % des rappels li√©s √† une cause d√©j√† observ√©e (ex: Listeria r√©currente). **Cible : 0%**. | **√âchec Correctif :** Un TRCR √©lev√© indique que les actions correctives (CAPA) pr√©c√©dentes n'ont pas √©t√© efficaces. N√©cessite un audit du processus de gestion des non-conformit√©s. |
        | **D√©rive des Causes Racines (DCR)** | Graphique de tendance du classement des motifs. | **Veille R√©glementaire :** Si un motif monte rapidement dans le classement (ex: √©tiquetage), cela peut indiquer un nouveau manquement r√©glementaire ou une d√©rive d'un fournisseur T1. |
        """)
    
    # --- KPI CONFORMIT√â (4 colonnes x 2 lignes = 8 KPIs) ---
    col1, col2, col3, col4 = st.columns(4)
    col5, col6, col7, col8 = st.columns(4)
    
    # LIGNE 1 : PRESSION & CONTEXTE
    with col1:
        st.metric("Total Rappels (Filtr√©)", total_rappels,
            help="Nombre total de fiches de rappel publi√©es, tenant compte de la p√©riode et des filtres s√©lectionn√©s. üìà **Message :** Mesure la **pression volume** globale.")
    with col2:
        st.metric("% Rappels Graves", pc_risques_graves_str,
            help="Proportion des rappels dont le risque est jug√© grave. üõë **Gravit√© :** Un taux √©lev√© justifie un renforcement imm√©diat des contr√¥les qualit√© critiques (CCP).")
    with col3:
        st.metric("Taux de R√©currence des Causes Racines (TRCR)", f"{trcr_value:.1f}%",
            help="Pourcentage des rappels dont la cause racine a d√©j√† √©t√© observ√©e dans le pass√©. üîÅ **Audit :** Un TRCR √©lev√© indique un **√©chec des actions correctives** et n√©cessite un audit du syst√®me qualit√©.")
    with col4:
        if not df_risques_exploded.empty:
            diversite_risques = df_risques_exploded['risques_encourus'].nunique()
            st.metric("Diversit√© des Risques", diversite_risques, 
                help="Nombre de types de risques encourus diff√©rents identifi√©s. ü§Ø **Syst√©mique :** Une grande diversit√© signale des probl√®mes de ma√Ætrise g√©n√©rale plut√¥t qu'un risque ponctuel.")
        else:
            st.metric("Diversit√© des Risques", "N/A", 
                help="Nombre de types de risques encourus diff√©rents identifi√©s. ü§Ø **Syst√©mique :** Une grande diversit√© signale des probl√®mes de ma√Ætrise g√©n√©rale plut√¥t qu'un risque ponctuel.")
        
    # LIGNE 2 : PERFORMANCE & PROJECTION
    with col5:
        st.metric("Volatilit√© IMR (IMR_STD)", f"{imr_std_value:.2f}",
            help="√âcart-type (STD) des valeurs mensuelles de l'IMR sur 6 mois. üé¢ **Stabilit√© :** Une forte volatilit√© indique que le risque n'est pas ma√Ætris√© et varie fortement d'un mois √† l'autre (impr√©visibilit√©).")
    with col6:
        df_vol = df_filtered.groupby(df_filtered["date_publication"].dt.to_period("M")).size().reset_index(name="Rappels")
        volatilite = df_vol["Rappels"].std() if not df_vol.empty and len(df_vol) > 1 else 0
        st.metric("Volatilit√© Mensuelle Rappel", f"{volatilite:.1f}",
            help="√âcart-type (STD) du nombre de rappels publi√©s chaque mois sur la p√©riode filtr√©e. üå™Ô∏è **Planification :** Une forte volatilit√© complique la planification des ressources de gestion de crise.")
    with col7:
        if "motif_du_rappel" in df_filtered.columns and "risques_encourus" in df_filtered.columns and not df_filtered.empty:
            df_temp_imr = df_filtered.copy()
            df_temp_imr["is_risque_grave"] = df_temp_imr["risques_encourus"].str.contains(risques_graves_keywords, case=False, na=False)
            df_temp_imr['score_gravite'] = np.where(df_temp_imr['is_risque_grave'], 2, 1)

            motif_graves = df_temp_imr.groupby('motif_du_rappel')['score_gravite'].mean().reset_index()
            top_motifs_graves = motif_graves.sort_values(by='score_gravite', ascending=False).head(1)
            
            rmpc = top_motifs_graves['score_gravite'].mean() * 10 if not top_motifs_graves.empty else 0.0
            st.metric("RMPC (Simul√©)", f"{rmpc:.2f}", help="Risque Moyen Pond√©r√© par Cat√©gorie (RMPC). üí° **Analyse :** Aide √† identifier les motifs qui, bien que peu fr√©quents, portent la plus grande charge de risque (gravit√© √©lev√©e).")
        else:
            st.metric("RMPC (Simul√©)", "N/A", help="Risque Moyen Pond√©r√© par Cat√©gorie (RMPC). üí° **Analyse :** Aide √† identifier les motifs qui, bien que peu fr√©quents, portent la plus grande charge de risque (gravit√© √©lev√©e).")
    with col8:
        st.metric("Ratio Risque/Opportunit√© (RRO)", f"{rro_value:.2f}",
            help="Simule si le niveau de risque (IMR) est justifi√© par l'activit√© dans la cat√©gorie. üöÄ **R&D :** Un score √©lev√© (mauvais) sugg√®re que l'entreprise prend des risques disproportionn√©s par rapport √† l'activit√© concurrentielle du secteur.")


    st.markdown("### 1. Tendance : D√©rive des Causes Racines (DCR) - Taux d'√âmergence des Motifs")
    st.markdown("---") # S√©paration visuelle
    
    if "date_publication" in df_filtered.columns and "motif_du_rappel" in df_filtered.columns:
        
        df_trend = df_filtered.copy()
        
        if df_trend.empty:
            st.info("‚ö†Ô∏è Les donn√©es filtr√©es sont vides pour l'analyse des tendances.")
        else:
            df_trend["Mois"] = df_trend["date_publication"].dt.to_period("M")
            
            df_motifs = explode_column(df_trend, "motif_du_rappel")
            
            if not df_motifs.empty:
                df_motifs = df_motifs.reset_index().rename(columns={'index': 'original_index'})
                df_motifs_merged = pd.merge(df_motifs, df_trend[['Mois']].reset_index().rename(columns={'index': 'original_index'}), on='original_index', how='left')
                
                motif_counts = df_motifs_merged.groupby(['Mois', 'motif_du_rappel']).size().reset_index(name='Rappels')
                motif_counts['Rang'] = motif_counts.groupby('Mois')['Rappels'].rank(method='first', ascending=False)
                
                top_motifs_global = motif_counts['motif_du_rappel'].value_counts().head(5).index
                df_rank = motif_counts[motif_counts['motif_du_rappel'].isin(top_motifs_global)].copy()
                
                df_rank['Mois'] = df_rank['Mois'].dt.to_timestamp()
                
                if not df_rank.empty:
                    fig_bump = px.line(df_rank, 
                                       x="Mois", 
                                       y="Rang", 
                                       color="motif_du_rappel", 
                                       line_shape='spline',
                                       markers=True,
                                       title="√âvolution du Classement (Rang) des 5 Principaux Motifs de Rappel",
                                       labels={"Rang": "Classement (1 = Plus Fr√©quent)", "Mois": "Mois"},
                                       color_discrete_sequence=px.colors.qualitative.Dark24)
                    
                    fig_bump.update_yaxes(autorange="reversed", tickvals=[1, 2, 3, 4, 5], title="Classement (1 = le plus fr√©quent)")
                    fig_bump.update_traces(marker=dict(size=10))
                    
                    st.plotly_chart(fig_bump, use_container_width=True)
                else:
                    st.info("Donn√©es insuffisantes pour la D√©rive des Causes Racines.")
            else:
                 st.info("Donn√©es de motif de rappel insuffisantes apr√®s nettoyage.")
    else:
        st.info("Colonnes manquantes pour l'analyse des motifs.")

    st.markdown("---") # S√©paration visuelle
    st.subheader("2. Profil de Risque (Radar Chart RMPC)")
    
    if "categorie_de_produit" in df_filtered.columns and "risques_encourus" in df_filtered.columns:
        df_radar = df_filtered.copy()
        
        if df_radar.empty:
            st.info("‚ö†Ô∏è Les donn√©es filtr√©es sont vides. Ajustez les filtres pour g√©n√©rer le Profil de Risque (Radar Chart).")
        else:
            df_radar['is_risque_grave'] = df_radar["risques_encourus"].str.contains(risques_graves_keywords, case=False, na=False)
            df_radar['score_gravite'] = np.where(df_radar['is_risque_grave'], 2, 1)

            cat_scores = df_radar.groupby('categorie_de_produit').agg(
                RMPC=('score_gravite', 'mean'),
                Frequence=('categorie_de_produit', 'count')
            ).reset_index()
            
            cat_scores['RMPC'] = cat_scores['RMPC'] * 10 
            
            top_cats = cat_scores.sort_values(by='Frequence', ascending=False).head(5)
            
            if not top_cats.empty:
                fig_radar = px.line_polar(top_cats, r='RMPC', theta='categorie_de_produit', line_close=True,
                                          title="Profil de Risque Moyen Pond√©r√© par Cat√©gorie (RMPC)",
                                          color_discrete_sequence=['#E67E22'])
                fig_radar.update_traces(fill='toself')
                fig_radar.update_layout(polar=dict(
                    radialaxis=dict(visible=True, range=[0, 20])
                ))
                st.plotly_chart(fig_radar, use_container_width=True)
            else:
                st.info("Donn√©es insuffisantes pour le Profil de Risque (Radar Chart) : aucune cat√©gorie fr√©quente identifi√©e.")
    else:
         st.info("Donn√©es de risque et/ou de cat√©gorie manquantes.")


st.markdown("---")

# --- 6. TABLEAU DE DONN√âES D√âTAILL√â ---
with st.expander("üîç Registre D√©taill√© des Rappels (Filtr√©)"):
    display_cols = [c for c in ["reference_fiche", "date_publication", "date_debut_commercialisation", "categorie_de_produit", "nom_marque_du_produit", "motif_du_rappel", "risques_encourus", "distributeurs", "zone_geographique_de_vente", "liens_vers_la_fiche_rappel"] if c in df_filtered.columns]
    
    st.dataframe(df_filtered[display_cols].sort_values(by="date_publication", ascending=False).reset_index(drop=True), use_container_width=True)

    csv = df_filtered[display_cols].to_csv(index=False).encode('utf-8')
    st.download_button(label="üíæ T√©l√©charger les Donn√©es Filtr√©es (CSV)", data=csv, file_name="recall_analytics_export_filtered.csv", mime="text/csv")


st.caption("Prototype Recall Analytics ‚Äî Donn√©es publiques (c) RappelConso.gouv.fr / Minist√®re de l'√âconomie")
